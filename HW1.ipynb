{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5811b06",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/63d62875-35ab-4447-8677-1945cbefcd8b\n",
    "https://chatgpt.com/share/81bf5858-15e8-4e70-9944-e723f03c6692\n",
    "https://chatgpt.com/share/6cd28703-68c7-491b-b852-4243d1374cc8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5cf5a8",
   "metadata": {},
   "source": [
    "# pre-lecture HW 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc6b423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb981ead",
   "metadata": {},
   "source": [
    "# pre-lecture HW 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4175509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = data.shape\n",
    "\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b40b8e",
   "metadata": {},
   "source": [
    "# pre-lecture HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f08862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of numerical columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get a summary of numerical columns\n",
    "print(\"Summary of numerical columns:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c067672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of categorical columns:\n",
      "             id     name gender species birthday personality          song  \\\n",
      "count       390      391    391     391      391         391           380   \n",
      "unique      390      391      2      35      361           8            92   \n",
      "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
      "freq          1        1    204      23        2          60            10   \n",
      "\n",
      "         phrase           full_id  \\\n",
      "count       391               391   \n",
      "unique      388               391   \n",
      "top     wee one  villager-admiral   \n",
      "freq          2                 1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get a summary of categorical columns\n",
    "print(\"\\nSummary of categorical columns:\")\n",
    "print(data.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ffe95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General info about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# General information about the DataFrame\n",
    "print(\"\\nGeneral info about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689f78b",
   "metadata": {},
   "source": [
    "# pre-lecture HW 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981b097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric variables:\n",
      "Index(['id', 'name', 'gender', 'species', 'birthday', 'personality', 'song',\n",
      "       'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values in numeric variables:\n",
      "row_n    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# (a) Check for non-numeric variables\n",
    "non_numeric_vars = data.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric variables:\")\n",
    "print(non_numeric_vars)\n",
    "\n",
    "# (b) Check for missing values in numeric variables\n",
    "missing_values_numeric = data.select_dtypes(include=[float, int]).isnull().sum()\n",
    "print(\"\\nMissing values in numeric variables:\")\n",
    "print(missing_values_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee93e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset\n",
    "shape = data.shape\n",
    "print(\"Dataset shape:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ebfed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics for numerical columns:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "Descriptive statistics for categorical columns:\n",
      "         sex embarked  class  who deck  embark_town alive\n",
      "count    891      889    891  891  203          889   891\n",
      "unique     2        3      3    3    7            3     2\n",
      "top     male        S  Third  man    C  Southampton    no\n",
      "freq     577      644    491  537   59          644   549\n"
     ]
    }
   ],
   "source": [
    "# Get the descriptive statistics for numerical columns\n",
    "describe_numeric = data.describe()\n",
    "\n",
    "# Get the descriptive statistics for categorical columns\n",
    "describe_categorical = data.describe(include=['object'])\n",
    "\n",
    "print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "print(describe_numeric)\n",
    "\n",
    "print(\"\\nDescriptive statistics for categorical columns:\")\n",
    "print(describe_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc80c5b",
   "metadata": {},
   "source": [
    "\"shape\" shows the nuber of row and column including numerical and non-numerical;\n",
    "\"descirbe\" shows only numerical columns and its desciption "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71320dcd",
   "metadata": {},
   "source": [
    "# pre-lecture HW 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b25b0",
   "metadata": {},
   "source": [
    "\"attribute\" gives the state and related information of object and can access directly, so it doesn't need ();\n",
    "\"method\" means the function to calculate or execute, and the () used for calling the function.\n",
    "    the difference of \"function\" between math and programing:\n",
    "        in programing: could have multiple input; the input can be changed and have multiple operations; may have more complicated logic. used for mission and execution.\n",
    "           in math: used for calcualting and have only one input-output relationship. no more complicated logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639b1e9",
   "metadata": {},
   "source": [
    "# post-lecture HW 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014b7b5",
   "metadata": {},
   "source": [
    "    1. Count:\n",
    "\tThe number of non-null (non-missing) entries in the column. This helps you understand how many valid (non-missing) data points are present for each variable.\n",
    "    \n",
    "\t2.\tMean:\n",
    "\tThe arithmetic average of the data. It’s calculated by summing all the values in the column and then dividing by the number of values (i.e., the count). It provides a measure of central tendency.\n",
    "    \n",
    "\t3.\tStandard Deviation (std):\n",
    "\tA measure of the spread or dispersion of the data from the mean. A higher standard deviation indicates more spread out values. It gives you a sense of how much the values deviate from the mean.\n",
    "    \n",
    "\t4.\tMin:\n",
    "\tThe smallest value in the column. It represents the minimum data point, or the lowest observed value.\n",
    "    \n",
    "\t5.\t25% (1st Quartile or Q1):\n",
    "\tThe first quartile (Q1), which is the value below which 25% of the data fall. This is also known as the 25th percentile and gives you a measure of the lower bound of the central 50% of the data.\n",
    "    \n",
    "\t6.\t50% (Median or 2nd Quartile or Q2):\n",
    "\tThe median, or the middle value of the data when it is sorted in ascending order. 50% of the data values are less than or equal to this value. Unlike the mean, the median is not affected by outliers.\n",
    "    \n",
    "\t7.\t75% (3rd Quartile or Q3):\n",
    "\tThe third quartile (Q3), which is the value below which 75% of the data fall. This is also known as the 75th percentile and gives you a measure of the upper bound of the central 50% of the data.\n",
    "    \n",
    "\t8.\tMax:\n",
    "\tThe largest value in the column. It represents the maximum data point, or the highest observed value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d665f2",
   "metadata": {},
   "source": [
    "# post-lecture HW 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0728f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Original shape: (891, 15)\n",
      "Cleaned shape: (712, 15)\n"
     ]
    }
   ],
   "source": [
    "#Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "df_cleaned = df.dropna(subset=['age', 'embarked'])\n",
    "\n",
    "# Check the shape of the original and cleaned dataframe\n",
    "print(f'Original shape: {df.shape}')\n",
    "print(f'Cleaned shape: {df_cleaned.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1513b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "177\n",
      "Index(['survived', 'pclass', 'sex', 'sibsp', 'parch', 'fare', 'embarked',\n",
      "       'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna() \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Inspect columns and check for missing values\n",
    "print(df.columns)\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Display missing values for 'age' column\n",
    "print(missing_values['age'])\n",
    "\n",
    "del df['age']\n",
    "\n",
    "# Check the remaining columns in the dataset\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253055c",
   "metadata": {},
   "source": [
    " #Discuss why applying del df['col'] before df.dropna() when both are used together could be important：\n",
    "\n",
    " del df['col'] can delate one useless column and decrease the Complexity of a dataset, whcih makes df.dropna() calculate easier and have less chance to lost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b7d7a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Inspect missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5aac35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (891, 14)\n",
      "Cleaned shape: (889, 14)\n",
      "Missing values after cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         0\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "embark_town      0\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Remove the column have the most missing values: \"deck\"\n",
    "del df['deck']\n",
    "\n",
    "# Drop rows with missing values in 'embark_town' (only have 2 missing values)\n",
    "df_cleaned = df.dropna(subset=['embark_town'])\n",
    "\n",
    "# Check the shape of the original DataFrame\n",
    "original_shape = df.shape\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "\n",
    "# Check the shape of the cleaned DataFrame\n",
    "cleaned_shape = df_cleaned.shape\n",
    "print(f\"Cleaned shape: {cleaned_shape}\")\n",
    "\n",
    "# Verify the absence of missing values\n",
    "missing_values_cleaned = df_cleaned.isnull().sum()\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(missing_values_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b684a",
   "metadata": {},
   "source": [
    "# post-lecture HW 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718852b",
   "metadata": {},
   "source": [
    "this code used for showing the related data between two columns, df.groupby(\"col1\") means choose one column first and set different groups, [\"col2\"] means choose this column from each groups, .describe() means calculating the information of col2 from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc04c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min        25%   50%    75%       max\n",
      "sex                                                                        \n",
      "female  314.0  44.479818  57.997698  6.75  12.071875  23.0  55.00  512.3292\n",
      "male    577.0  25.523893  43.138263  0.00   7.895800  10.5  26.55  512.3292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and get descriptive statistics for 'fare'\n",
    "grouped_stats = df.groupby(\"sex\")[\"fare\"].describe()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d442e",
   "metadata": {},
   "source": [
    "this code only cares about 2 columns but df.describe() cares about whole dataset. that's the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49c8d8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Group by 'sex' and get descriptive statistics for 'fare'\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m grouped_stats \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43mSex\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfare\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_stats)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sex' is not defined"
     ]
    }
   ],
   "source": [
    "# mistake trying\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and get descriptive statistics for 'fare'\n",
    "grouped_stats = df.groupby(Sex)[\"fare\"].describe()\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f4ae8",
   "metadata": {},
   "source": [
    "not import pandas as pd: same speed, it is a simple question.\n",
    "\n",
    "wrong URL: Chatbot is faster, it is hard to notice such small mistake of URL so I don't know how to search solution on Google.\n",
    "\n",
    "use DF instead of df: nothing happened.\n",
    "\n",
    "forgot parentheses: Chatbot is faster because there are too many different results on Google and click it one by one is much slower than Chatbot.\n",
    "\n",
    "spelling mistake of function: Chatbot is faster because it is more targeted to a sepcific spelling mistake.\n",
    "\n",
    "spelling mistake of column name: Chatbot is faster because it gives you directly answer and it is difficult to describe the error on Google.\n",
    "\n",
    "Omit quotation marks: Chatbot is faster because there are too many different results on Google and click it one by one is much slower than Chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d743c",
   "metadata": {},
   "source": [
    "# post-lecture HW 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10a1d0",
   "metadata": {},
   "source": [
    "somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
